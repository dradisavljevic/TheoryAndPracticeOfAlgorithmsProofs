\documentclass{article}

\usepackage{amsmath,amsthm,amssymb}

\newcommand{\Lim}[1]{\raisebox{0.5ex}{{$\displaystyle \lim_{#1}\;$}}}
\newcommand{\subtitle}[1]{%
  \posttitle{%
    \par\end{center}
    \begin{center}\LARGE#1\end{center}
    \vskip0.5em}%
}

\begin{document}
\subtitle{Lecture I}\\
\noindent \textbf{Exercise 1.1} Prove or disprove the following: $f(x) = o(g(n))$ if and only if $\Lim{n \to \infty} \frac{f(n)}{g(n)}=0$.
\begin{proof}
  Let $\Lim{n \to \infty} \frac{f(n)}{g(n)}=0$, meaning that as n increases towards infinity, $\frac{f(n)}{g(n)}$ approaches 0. This means that in order for this to be true, the following statement must be true $g(n) > f(n)$ for very large n, so that the fraction $\frac{f(n)}{g(n)}$ is sufficiently small. In other words, $g(n)$ grows faster than $f(n)$ which can be expressed as $f(x) = o(g(n))$. \\
  
  Now let $\Lim{n \to \infty} \frac{f(n)}{g(n)}\neq0$ meaning that as n increases limit of the fraction $\frac{f(n)}{g(n)}$ equals to either some constant $c$ that is not 0 or approaches infinity. In the first case, where limit yields a constant $c$, it can be written as both $\Lim{n \to \infty} \frac{f(n)}{g(n)}>0$ and $\Lim{n \to \infty} \frac{f(n)}{g(n)}<\infty$ meaning that $g(n)$ is both upper and lower bound of $f(n)$, or in other words an exact bound, which can be written as $f(x) = \Theta(g(n))$. Since $g(n)$ is an upper bound of $f(n)$, this means that $f(x) \neq o(g(n))$. In the case of the limit being equal to infinity for a very large n, the statement $g(n) < f(n)$ must hold true, in other words $f(x) = O(g(n))$, which further implies $f(x) \neq o(g(n))$. In both cases we have that if $\Lim{n \to \infty} \frac{f(n)}{g(n)}\neq0$ then also $f(x) \neq o(g(n))$. \\
  
  Considering both $\Lim{n \to \infty} \frac{f(n)}{g(n)}=0 \implies f(x) = o(g(n))$ and $\Lim{n \to \infty} \frac{f(n)}{g(n)}\neq0 \implies f(x) \neq o(g(n))$, we can say that $f(x) = o(g(n)) \iff \Lim{n \to \infty} \frac{f(n)}{g(n)}=0$ which is what was needed to be proven.

\end{proof}
\noindent\rule{12cm}{0.4pt}\\
\noindent \textbf{Exercise 1.2} Let $\mathcal{M}_n$ = ($M_n$,$+_n$,$\mathrm{x}_n$,$0_n$,$\mathrm{I}_n$). Then we have $\mathcal{M}_n$ is a ring with identity element $\mathrm{I}_n$ if and only if $\mathcal{R}$ is ring with 1.
\begin{proof}
  Let $\mathcal{R}$ = ($R$,$\circ$,$\mathcal{*}$,0,1) be a ring with 1. This means that $\mathcal{R}$ has following properties:\\
  \begin{itemize}
  \item Both $\circ$ and $\mathcal{*}$ operations are associative and closed over $R$.
  \item $\circ$ (Additive operation) is commutative.
  \item $\mathcal{*}$ (Multiplicative operation) is distributive with respect to $\circ$.
  \item 0 is neutral element with respect to $\circ$.
  \item 1 is identity element with respect to $\mathcal{*}$.
  \item For every $a$, where $a \in R$, there is an additive inverse $\neg a$ such that $a\circ\neg a=0$.
  \end{itemize}
  $M_n$ is defined as set of $ n\ \mathrm{x}\ n$ matrices over $R$ with $+_n$ and $\mathrm{x}_n$ being square matrix equivalent of additive and multiplicative operations, respectively, present in ring $\mathcal{R}$. Let matrices $\mathcal{A}$ and $\mathcal{B}$ be members of $M_n$ such that
  $\mathcal{A}= \begin{bmatrix}
 	a & b\\
 	c & d
 \end{bmatrix}$, $\mathcal{B}= \begin{bmatrix}
 	e & f\\
 	g & h
 \end{bmatrix}$ and $\mathcal{C}= \begin{bmatrix}
 	i & j\\
 	k & l
 \end{bmatrix}$. Applying the additive and multiplicative operations between these matrices we have: \\\\
 $\begin{pmatrix} \begin{bmatrix}
 	a & b\\
 	c & d
 \end{bmatrix}$ $+_n$ $\begin{bmatrix}
 	e & f\\
 	g & h
 \end{bmatrix} \end{pmatrix}$ $+_n$ $\begin{bmatrix}
 	i & j\\
 	k & l
 \end{bmatrix}$ = $\begin{bmatrix}
 	a\circ e\circ i & b\circ f\circ j\\
 	c\circ g\circ k & d\circ h\circ l
 \end{bmatrix}$ \\\\\\
 $ \begin{bmatrix}
 	a & b\\
 	c & d
 \end{bmatrix}$ $+_n$ $\begin{pmatrix} \begin{bmatrix}
 	e & f\\
 	g & h
 \end{bmatrix}$ $+_n$ $\begin{bmatrix}
 	i & j\\
 	k & l
 \end{bmatrix} \end{pmatrix}$ = $\begin{bmatrix}
 	a\circ e\circ i & b\circ f\circ j\\
 	c\circ g\circ k & d\circ h\circ l
 \end{bmatrix}$ \\\\\\
  $\begin{bmatrix}
 	a & b\\
 	c & d
 \end{bmatrix}$ $\mathrm{x}_n$ $\begin{bmatrix}
 	e & f\\
 	g & h
 \end{bmatrix}$ = $\begin{bmatrix}
 	(a\mathcal{*} e) \circ (b\mathcal{*} g) & (a\mathcal{*} f) \circ (b\mathcal{*} h)\\
 	(c\mathcal{*} e) \circ (d\mathcal{*} g) & (c\mathcal{*} f) \circ (d\mathcal{*} h)
 \end{bmatrix}$\\\\\\
  $\begin{bmatrix}
 	a & b\\
 	c & d
 \end{bmatrix}$ $+_n$ $\begin{bmatrix}
 	0 & 0\\
 	0 & 0
 \end{bmatrix}$ = $\begin{bmatrix}
 	a \circ 0 & b \circ 0\\
 	c \circ 0 & d \circ 0
 \end{bmatrix}$\\\\\\
  $\begin{bmatrix}
 	a & b\\
 	c & d
 \end{bmatrix}$ $\mathrm{x}_n$ $\begin{bmatrix}
 	1 & 0\\
 	0 & 1
 \end{bmatrix}$ = $\begin{bmatrix}
 	(a\mathcal{*} 1) \circ (b\mathcal{*} 0) & (a\mathcal{*} 0) \circ (b\mathcal{*} 1)\\
 	(c\mathcal{*} 1) \circ (d\mathcal{*} 0) & (c\mathcal{*} 0) \circ (d\mathcal{*} 1)
 \end{bmatrix}$\\\\\\
From this it can be seen that additive operation is both closed and associative. Additionally it can be seen that additive operation is commutative if the $\circ$ operation is commutative. Due to the fact that multiplication of matrices is associative, it can be deduced that $\mathrm{x}_n$ is associative if both $\circ $ and $\mathcal{*}$ are associative.\\
Taking into consideration that matrix multiplication is distributive in respect to matrix addition we have that $\mathrm{x}_n$ is distributive in respect to $+_n$ if $\mathcal{*}$ is in respect to $\circ $. \\
Additionally, we can see from the above equations that $0_n$ is a neutral element with respect to $+_n$ if 0 is neutral element with respect to $\circ$, while $\mathrm{I}_n$ is identity element with respect to $\mathrm{x}_n$ if 1 is identity element with respect to $\mathcal{*}$.\\
Lastly, if we consider the example of matrix addition above it can be seen that in order for additive inverse to exist, all that is necessary is for the two matrices $\mathcal{A}$ and $\mathcal{B}$ one of them to contain negative elements of the other ones, which relies on elements from $R$ having an additive inverse.\\
Thus we can conclude that if $\mathcal{R}$ is a ring with identity, $\mathcal{M}$ also is.\\
The opposite direction, that when $\mathcal{R}$ is not a ring with identity $\mathcal{M}$ is easily noticed, since all the operations in $\mathcal{M}$ rely on properties of operations in  $\mathcal{R}$ in order to fulfill conditions of a ring.
\end{proof}
\noindent\rule{12cm}{0.4pt}\\
\noindent \textbf{Exercise 1.3} Show that the definition of $+$ and $\cdot$ over $\mathbb{Z}_m$ are independent of the choice of the representation.
\begin{proof}
Sadly I have no idea how to prove this at current point.
\end{proof}
\noindent\rule{12cm}{0.4pt}\\
\noindent \textbf{Exercise 1.4} Prove or disprove: Let $(G, \circ)$ be any Abelian group, let $a \in G$, and let $n, m \in \mathbb{N}$. If $a$ has the order $n$ then $a^m=e$ if and only if $m \equiv 0$ mod $n$.
\begin{proof}
Suppose that $a$ has the order $n$. That would mean that $n$ is a smallest positive integer for which the statement $a^n=e$ holds true. Next let's suppose that $a^m=e$. This would mean that $a^n \equiv a^m$ mod n, which when applying \textbf{Theorem 1.5} would mean that $\prod_{i=1}^{m} a \equiv \prod_{i=1}^{n} a$ mod n, so $m$ would have to be divisible by $n$, or in other words $m \equiv 0$ mod $n$.\\
Now let's suppose that $m \equiv 0$ mod $n$ and $a^m=e$, this would mean that $m$ is either order of the group $G$ or a number larger than the one that is order. Next we have two cases $m=n$ and $m \neq n$. In first case, $n=m$ is order of $G$, and the exercises has been proven.\\
The second case is such that we can rewrite $m$ as $m=c\cdot n$ for some integer $c$, due to it being divisible by n. Considering $a^m=e$ we can rewrite it as ${a^n}^c$ which in turn we can write as $a^n=e^{1/c}$ which is equal to writing $a^n=e$, meaning $n$ is order of $a$.
\end{proof}
\noindent\rule{12cm}{0.4pt}\\
\noindent \textbf{Exercise 1.5} Show that $\sum_{k=0}^{998} k^{3}$ is divisible by 999.
\begin{proof}
	
\end{proof}




\end{document}